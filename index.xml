<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>//iwate.github.io</title>
    <link>https://iwate.github.io/index.xml</link>
    <description>Recent content on //iwate.github.io</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <copyright>&amp;copy; &lt;a href=&#34;https://github.com/iwate&#34;&gt;iwate&lt;/a&gt; 2016</copyright>
    <lastBuildDate>Fri, 23 Dec 2016 19:00:59 +0900</lastBuildDate>
    <atom:link href="https://iwate.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Service Fabric Performance and Scalability samplesの結果を見る</title>
      <link>https://iwate.github.io/post/service-fabric-5/</link>
      <pubDate>Fri, 23 Dec 2016 19:00:59 +0900</pubDate>
      
      <guid>https://iwate.github.io/post/service-fabric-5/</guid>
      <description>

&lt;p&gt;これはAzure AdventCalender 24日目です。
今回は、&lt;a href=&#34;https://github.com/Azure-Samples/service-fabric-dotnet-performance&#34;&gt;Service Fabric Performance and Scalability samples&lt;/a&gt;を実行してみて、その結果を見てみたいと思います。&lt;/p&gt;

&lt;h2 id=&#34;service-fabric-performance-and-scalability-samples&#34;&gt;Service Fabric Performance and Scalability samples&lt;/h2&gt;

&lt;p&gt;Service Fabricのサンプルの一つで、最近出ました。このサンプルでは、Reliable DictionaryとActorのそれぞれReadWriteの時間を計測できます。
今回は、Reliable Dictionaryを計測します。&lt;/p&gt;

&lt;p&gt;この計測の流れは、クライアントがLoadDriverと呼ばれるサービスに計測リクエストをなげて、LoadDriverがSatefullServiceとのやり取りを行って計測して、結果をクライアントが受け取るというコードになってます。&lt;/p&gt;

&lt;p&gt;このサンプルで面白いなと思ったのは、&lt;code&gt;WcfCommunicationListener&lt;/code&gt;を使って&lt;code&gt;FabricClient&lt;/code&gt;がサービスとやり取りをしているところです。
WcfCommunicationListenerを初めて聞いたとき、「いまさらWCF&amp;hellip;」って思ったのですが、なるほどこんな風に使うんですね。&lt;/p&gt;

&lt;h2 id=&#34;計測環境&#34;&gt;計測環境&lt;/h2&gt;

&lt;p&gt;次の2つの環境で計測しました。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;SF Version&lt;/th&gt;
&lt;th&gt;CPU&lt;/th&gt;
&lt;th&gt;Memory&lt;/th&gt;
&lt;th&gt;Nodes&lt;/th&gt;
&lt;th&gt;Machines&lt;/th&gt;
&lt;th&gt;Partitions&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Local1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Intel® core™ i5-6500 @ 3.2 GHz&lt;/td&gt;
&lt;td&gt;16GB&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Local2&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Intel® core™ i5-6500 @ 3.2 GHz&lt;/td&gt;
&lt;td&gt;16GB&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Cloud&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Intel® Xeon™ E5-2673 v3 @ 2.4 GHz&lt;/td&gt;
&lt;td&gt;4GB&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Cloudの方は最近出た&lt;code&gt;A2_v2&lt;/code&gt;インスタンスです。 Localでは、Reliable DicrionaryのPartitionsサイズを1とCore数分の二つで計測してみました。(計測を始めるとCPUが100%に張り付くのが気になったので)&lt;/p&gt;

&lt;p&gt;Cloudはデフォの6のままです。&lt;/p&gt;

&lt;p&gt;パラメータは次のように設定しました。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;Parameter&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Value&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;NumWriteOperationsTotal&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;262144&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Total number of write operations to be performed on the service.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;NumOutstandingWriteOperations&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;64&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Number of write operations sent to the service at any given time.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;NumReadOperationsTotal&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;524288&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Total number of read operations to be performed on the service.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;NumOutstandingReadOperations&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;16&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Number of read operations sent to the service at any given time.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;OperationDataSizeInBytes&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1024&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Size in bytes of the data associated with each operation (i.e. read or write) performed on the service.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;NumItems&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2048&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Number of items (e.g. number of rows in a table) that the operations are distributed across in the service.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;NumClients&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Number of clients used to perform the operations on the service.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;NumOutstandingWriteOperations が64の場合、64個のタスクが生成されて並行に操作がNumWriteOperationsTotal回実行されます。Readのほうもしかり。&lt;/p&gt;

&lt;h2 id=&#34;計測結果&#34;&gt;計測結果&lt;/h2&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th&gt;Test Case&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Time&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Operations&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ava. Operaions [ope/sec]&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ava. Operation Latency [ms]&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Local1&lt;/td&gt;
&lt;td&gt;Write&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;00:01:45.9455085&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;262144&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2474.32858373604&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;25.8481560119629&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Local1&lt;/td&gt;
&lt;td&gt;Read&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;00:01:04.9925570&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;524288&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8066.89295206527&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.9822887878418&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Local2&lt;/td&gt;
&lt;td&gt;Write&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;00:02:33.0721881&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;262144&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2474.32858373604&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;37.3323948471069&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Local2&lt;/td&gt;
&lt;td&gt;Read&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;00:01:27.1474273&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;524288&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6016.10416100029&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.65598070163727&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Cloud&lt;/td&gt;
&lt;td&gt;Write&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;00:04:04.4822671&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;262144&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1072.24136584424&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;59.5640092216492&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Cloud&lt;/td&gt;
&lt;td&gt;Read&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;00:03:24.7382677&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;524288&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2560.7718864176&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6.24372196731567&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;考察&#34;&gt;考察&lt;/h2&gt;

&lt;p&gt;これから、友達と鍋パなので手短に！
Local2がLocal1より時間かかったのはやっぱり、マシン一台なのにパーティション切ったのがいけないかなと。
全体的にやっぱり、書き込みが遅いですね。&lt;a href=&#34;https://iwate.github.io/post/service-fabric-2/&#34;&gt;前に計測したとき&lt;/a&gt;はヘッダに時間がかかってそうで、１件ずつとかかなり遅いって感じでした。
今回のサンプルでは最初の一件目にどれだけかかってるか出てないし、クラスタのVMSizeが異なるので素直に比較はできませんが、100k件が32880[ms]だったので、&lt;/p&gt;

&lt;p&gt;32880 * 2.62144 = 86192.9472 = 00:01:26.1929472&lt;/p&gt;

&lt;p&gt;という感じでしょうか。今回は、リバースプロキシなどを経由している点を考慮すると前回とった結果とあんまり変わらなさそうです。&lt;/p&gt;

&lt;p&gt;Cloudですごく結果が悪く見えます。Av2のCPUはDv2と同じなので、メモリかネットワークですかね。Localの時みたいにPatitionが分かれすぎってのもあるかも。&lt;/p&gt;

&lt;p&gt;今、Reliable Collection回りは中の人が頑張って書き直しいるそうなので（ほんとか？）、SDK上がるたびに計測できるようにいい感じの計測サービスを準備しておきたい今日この頃です。&lt;/p&gt;

&lt;p&gt;以上！結果書いただけかよ！って感じですが２４日目でした！&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Service Fabric Local Clusterのリバースプロキシのポートは19081|19083|19085|19087|19089</title>
      <link>https://iwate.github.io/post/service-fabric-4/</link>
      <pubDate>Tue, 01 Nov 2016 22:06:54 +0900</pubDate>
      
      <guid>https://iwate.github.io/post/service-fabric-4/</guid>
      <description>&lt;p&gt;書きたい内容はたいとるそのまんまです。Service Fabricにはリバースプロキシがあり、アプリケーション名でノードのIPを引けるようになっています。
Local Clusterにおけるリバースプロキシはデフォルト設定(v2.3.301)では19081、19083、19085、19087、もしくは、19089です。
1Nodeで動かしてるなら19801です。
&lt;/p&gt;

&lt;h2 id=&#34;リバースプロキシ&#34;&gt;リバースプロキシ&lt;/h2&gt;

&lt;p&gt;詳しくは→&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/service-fabric-reverseproxy/&#34;&gt;Reverse Proxy&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/Azure-Samples/service-fabric-dotnet-getting-started/tree/master/Services/WordCount&#34;&gt;サンプルのWordCount&lt;/a&gt;では&lt;a href=&#34;https://github.com/Azure-Samples/service-fabric-dotnet-getting-started/blob/master/Services/WordCount/WordCount.WebService/PackageRoot/ServiceManifest.xml&#34;&gt;ServiceManifest&lt;/a&gt;で起動するポートを指定していますが、Service Fabricを使っているなら、一つのアプリケーションバイナリをデプロイしておいて、&lt;a href=&#34;https://msdn.microsoft.com/en-us/library/azure/dn707676.aspx&#34;&gt;テナントごとにアプリケーションを作る&lt;/a&gt;、マルチテナント向きな使い方をしたいところです。
それには、ポートが固定されていては困るので、ダイナミックにポートを割り当ててリバースプロキシ経由でアクセスするときれいです。&lt;/p&gt;

&lt;p&gt;例えば、下図のようにアプリケーションが展開されているとします。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://iwate.github.io/images/service-fabric-4/applications.png&#34; alt=&#34;Applications&#34; /&gt;&lt;/p&gt;

&lt;p&gt;リバースプロキシ(&lt;a href=&#34;http://localhost:19081)にサービスのURIから`fabric:`以下を問い合わせると目当てのサービスに到達できます。&#34;&gt;http://localhost:19081)にサービスのURIから`fabric:`以下を問い合わせると目当てのサービスに到達できます。&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://iwate.github.io/images/service-fabric-4/wordcount.png&#34; alt=&#34;WordCount&#34; /&gt;&lt;/p&gt;

&lt;p&gt;うーん。いいですね！(๑╹ڡ╹๑)&lt;/p&gt;

&lt;h2 id=&#34;19081から変えたい&#34;&gt;19081から変えたい&lt;/h2&gt;

&lt;p&gt;デフォルト設定から別のポートへ変更したい場合は&lt;code&gt;C:\SfDevCluster\Data\clusterManifest.xml&lt;/code&gt;を編集します。
&lt;code&gt;HttpApplicationGatewayEndpoint&lt;/code&gt;の&lt;code&gt;Port属性&lt;/code&gt;を好みに編集しましょう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;clusterManifest
  ...
  &amp;lt;NodeTypes&amp;gt;
    &amp;lt;NodeType Name=&amp;quot;NodeType0&amp;quot;&amp;gt;
      &amp;lt;Endpoints&amp;gt;
        ...
        &amp;lt;HttpApplicationGatewayEndpoint Port=&amp;quot;19081&amp;quot; Protocol=&amp;quot;http&amp;quot; /&amp;gt;
        ...
    ...
  ...
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;本番環境&#34;&gt;本番環境&lt;/h2&gt;

&lt;p&gt;まず、&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/service-fabric-reverseproxy/#_-4&#34;&gt;リバースプロキシを有効にします&lt;/a&gt;。
AzureにService Fabric Clusterを作成した場合、19008(もしくは設定したポート)にアクセスすればApplication Gatewayが動いてるノードで引いてくれます。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>好みのjs frontほにゃららを探して１</title>
      <link>https://iwate.github.io/post/js-framework-1/</link>
      <pubDate>Fri, 07 Oct 2016 13:11:59 +0900</pubDate>
      
      <guid>https://iwate.github.io/post/js-framework-1/</guid>
      <description>&lt;p&gt;仕事はECのプラットフォームの作成なので、やっぱりWEB。そうするとReact+Flux/ReduxやらAngularやらの話はやっぱり敏感になるのだけれど、多くの人と同様に「これは未来だ！」と感動したり、躓いては「これはなんか違う」って思ってる。
色々試してみて、全部に共通してると感じたのは&lt;strong&gt;コンポーネント&lt;/strong&gt;を作ってパーツ化して再利用しやすくするということ。これは大賛成。 でもまだやっぱりしっくりこないなあと思っているので原因を考えてみる。
&lt;/p&gt;

&lt;h2 id=&#34;一番しっくりきたのはriot-js&#34;&gt;一番しっくりきたのはRiot.js&lt;/h2&gt;

&lt;p&gt;React+Flux/Redux, Angular2, WebComponents+Polymer, Riot.jsを試してみて一番しっくりきたのはRiot.jsだった。WebComponents+Polymerもよかったけど、少し遅いしまだ早いと思った。もしこれがブラウザネイティブになるなら喜んで使うけど。
React+Flux/Reduxは初めて試したときはとても感動した。Reduxなんかとくに。Pureな関数だけを実装することで状態を制御して、それゆえに見通しが良くなるのがすごくいい。 ただやっぱりJSXはなれなかった。
Angular2はすべてががっちり固まってるのがつかれる。Reactと違ってテンプレート使えるのは受け入れやすかったけど。&lt;/p&gt;

&lt;p&gt;そこでRiot.js。Riot.jsは軽量だし、WebComponentsをいい感じに実現できるしVirtualDOMで今っぽくてよかった。&lt;/p&gt;

&lt;p&gt;Riot.jsでカスタムタグを作るとこんな感じ。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;custom-tag&amp;gt;
  &amp;lt;h1 onclick={changeMsg}&amp;gt;{message}&amp;lt;/h1&amp;gt;

  &amp;lt;script&amp;gt;
    this.message = &amp;quot;Hello, World!&amp;quot;;
    this.changeMsg = function(){
      this.message = &amp;quot;Hello, Riot.js&amp;quot;;
      this.update();
    }
  &amp;lt;/script&amp;gt;
&amp;lt;/custom-tag&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;riot-js最高って考えてた時期もありました&#34;&gt;Riot.js最高って考えてた時期もありました。&lt;/h2&gt;

&lt;p&gt;そう。最高って思ってた。でも次のいくつか問題にあたってからは「おしいなあ」って気持ちしかない。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;カスタムタグのネストがつらい&lt;/li&gt;
&lt;li&gt;他のJSライブライリとの相性の悪さ&lt;/li&gt;
&lt;li&gt;ifの値falseでもレンダリングが走る&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;まず、カスタムタグのネストがつらいと感じた。できるんだけどおしい。例えば次のようなにHTMLをかいてレンダリングすることを考えてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;custom-tag1&amp;gt;
  &amp;lt;custom-tag2&amp;gt;
    &amp;lt;custom-tag3/&amp;gt;
  &amp;lt;/custom-tag2&amp;gt;
&amp;lt;/custom-tag1&amp;gt;
&amp;lt;script&amp;gt;
  riot.render(&#39;*&#39;);
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この書き方自体はうまくいくし描画もされるのだけれど、custom-tag3は3回描画されます。 ちなみにcustom-tag2は2回、custom-tag1は1回です。それぞれ1回ずつ描画されることを期待しますけどそうじゃないんですよね。
これは&lt;code&gt;riot.render(&#39;*&#39;)&lt;/code&gt;が良くないとも言えますが、まあそこは掘り下げず、3回呼ばれるとまずい場合があるのかということから。&lt;/p&gt;

&lt;p&gt;ネスト回数分だけレンダリングが走ってしまうと、AJAXなどで外部からデータをロードするようなタグがこまる。ネスト回数分おんなじリクエスト飛ばすんかい！？ってなっちゃう。（そんなタグを作るでない！とも言える）&lt;/p&gt;

&lt;p&gt;2つ目の他のJSライブライリとの相性の悪さってのも1つ目のやつに起因しているのだけれど、何回も初期化コードが走ってほしくないものがある。例えば、エディタ系。 monaco-editorをタグ化したのだけれど、monaco-editorはDOMを内部で生成するからネスト回数分エディターが作られちゃう。&lt;/p&gt;

&lt;p&gt;3つ目は、次のようなコードをレンダリングさせたとき、custom2の方もレンダリング処理が走るということ。もちろん、custom2のif条件はfalseなので描画はされないが、custom-tagのレンダリング処理は実行されるので、無駄な処理が走る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;custom-tag id=&amp;quot;custom1&amp;quot; if={true} /&amp;gt;
&amp;lt;custom-tag id=&amp;quot;custom2&amp;quot; if={false} /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;つまり、Riot.jsは今はあまりネストしないほうがいいし、ajaxするようなコードは書かないほうがいいし、DOMが生成される既存の外部ライブラリを含めないほうがいいし、もちろん思い処理は含めないほうがいい。
でもこれってしたいよね。特にajaxとか。指定のJSONをロードするselect-boxとか作りたいじゃん？&lt;/p&gt;

&lt;h2 id=&#34;ajaxコールって関数じゃなくてやっぱりオブジェクトだよね&#34;&gt;Ajaxコールって関数じゃなくてやっぱりオブジェクトだよね。&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;fetch&lt;/code&gt;とか&lt;code&gt;$.ajax&lt;/code&gt;とか使いやすいし、今までなんとなくこっちのほうが、&lt;code&gt;XMLHttpRequst&lt;/code&gt;よりもあるべき姿と漠然と思ってた。だけど、やっぱり通信って状態から縁を切れないよね。そうするとreduxみたいにmiddlewareの中に押し込むのどうなんだろう？って感じた。&lt;/p&gt;

&lt;p&gt;じゃあリクエストをストアにためるのはどうかというと、状態を自己改変するからreduxだと扱えない（扱うべきでない）のかなと。そしたらやっぱりmiddlewareに落ち着くよね。&lt;/p&gt;

&lt;h2 id=&#34;もう文章グダグダだけど&#34;&gt;もう文章グダグダだけど&lt;/h2&gt;

&lt;p&gt;そんなこんなで、しっくりくる実装を今日も考えてる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ReliableConcurrentQueueを使う</title>
      <link>https://iwate.github.io/post/service-fabric-3/</link>
      <pubDate>Mon, 26 Sep 2016 12:49:42 +0900</pubDate>
      
      <guid>https://iwate.github.io/post/service-fabric-3/</guid>
      <description>&lt;p&gt;13日の更新で新しくPreviewになったReliableConcurrentQueueを試してみる。
&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://blogs.msdn.microsoft.com/azureservicefabric/2016/09/13/release-of-service-fabric-sdk-2-2-207-and-runtime-5-2-207/&#34;&gt;https://blogs.msdn.microsoft.com/azureservicefabric/2016/09/13/release-of-service-fabric-sdk-2-2-207-and-runtime-5-2-207/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;reliablequeueとの違い&#34;&gt;ReliableQueueとの違い&lt;/h2&gt;

&lt;p&gt;ReliableConcurrentQueueはFirst In First Outの順序がベストエフォートになっており、ReliableQueueのように厳密ではない分、複数のConsumerとProducerが同時実行できるようになっているようです。&lt;/p&gt;

&lt;h2 id=&#34;コード&#34;&gt;コード&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-cs&#34;&gt;using Microsoft.ServiceFabric.Data.Collections.Preview;
var queue = await this.StateManager.GetOrAddAsync&amp;lt;IReliableConcurrentQueue&amp;lt;string&amp;gt;&amp;gt;(&amp;quot;myQueue&amp;quot;);
var count = queue.Count; // プロパティでカウントがとれる
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ReliableQueueとはインターフェースが若干違い、カウントをとるのは&lt;code&gt;GetCountAsync&lt;/code&gt;メソッドではなく&lt;code&gt;Count&lt;/code&gt;プロパティでとれるようになっています。また、&lt;code&gt;TryPeekAsync&lt;/code&gt;メソッドはなくピーク処理（削除なしに先頭を読む）はできなくなっています。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ReliableDictionaryのWrite速度の調査</title>
      <link>https://iwate.github.io/post/service-fabric-2/</link>
      <pubDate>Sun, 25 Sep 2016 00:56:10 +0900</pubDate>
      
      <guid>https://iwate.github.io/post/service-fabric-2/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://iwate.github.io/post/service-fabric-1&#34;&gt;前回&lt;/a&gt;ReliableDictionaryの走査速度を調査するときに、Writeするのがすごく遅かったので手元のMacBookと&lt;a href=&#34;http://tryazureservicefabric.westus.cloudapp.azure.com/&#34;&gt;Party Cluster&lt;/a&gt;で計測した。
&lt;/p&gt;

&lt;h2 id=&#34;結果&#34;&gt;結果&lt;/h2&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;件数&lt;/th&gt;
&lt;th&gt;Macでの所要時間[ms]&lt;/th&gt;
&lt;th&gt;PartyClusterでの所要時間[ms]&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;183&lt;/td&gt;
&lt;td&gt;191&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;td&gt;306&lt;/td&gt;
&lt;td&gt;217&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;1k&lt;/td&gt;
&lt;td&gt;926&lt;/td&gt;
&lt;td&gt;318&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;10k&lt;/td&gt;
&lt;td&gt;10289&lt;/td&gt;
&lt;td&gt;2774&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;100k&lt;/td&gt;
&lt;td&gt;122100&lt;/td&gt;
&lt;td&gt;32880&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;1M&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&#34;https://iwate.github.io/images/service-fabric-2/1.png&#34; alt=&#34;結果&#34; /&gt;&lt;/p&gt;

&lt;p&gt;100万件の挿入/更新は前回と同様にサービスが途中で再起動してしまので取れてない。&lt;/p&gt;

&lt;h2 id=&#34;考察&#34;&gt;考察&lt;/h2&gt;

&lt;p&gt;まず、Party Clusterのほうが速い。Party Clusterのインスタンスは&lt;a href=&#34;https://github.com/Azure-Samples/service-fabric-dotnet-management-party-cluster/blob/master/ARM/PartyClusterServiceTemplate.json&#34;&gt;ARMみたかんじ&lt;/a&gt;Standard_D1かなあ。&lt;/p&gt;

&lt;p&gt;でもそれはどうでもよくて、1000件くらいまでは結構すんなり入るけど、1万件になると急に時間がかかってるように見えるのが気になる。これは、Keyでソートしてるせいかな？（余談だけど、Keyの順序をランダムに挿入しても、Enumeratorで取り出すと順番に取得できる。）&lt;/p&gt;

&lt;p&gt;あと1件あたりの時間も気になる。1件挿入/更新するのに180[ms]かかるってのどうよ？&lt;/p&gt;

&lt;p&gt;あ、でも、10万件の時の所要時間を1件単位にならすと1[ms]ぐらいなのでそこまで悪くないのかもしれない。&lt;/p&gt;

&lt;p&gt;次のような計算をして、初期時間を省いた1件あたりにかかる時間を出してみた。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;(N件のタイム - 1件のタイム) / (N件 - 1)  &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; N := 100, 1000, 10000, 100000, 100000&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;件数&lt;/th&gt;
&lt;th&gt;Macでの所要時間[ms]&lt;/th&gt;
&lt;th&gt;PartyClusterでの所要時間[ms]&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;td&gt;1.24&lt;/td&gt;
&lt;td&gt;0.262&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;1k&lt;/td&gt;
&lt;td&gt;0.689&lt;/td&gt;
&lt;td&gt;0.112&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;10k&lt;/td&gt;
&lt;td&gt;1.04&lt;/td&gt;
&lt;td&gt;0.273&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;100k&lt;/td&gt;
&lt;td&gt;1.24&lt;/td&gt;
&lt;td&gt;0.335&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;うん、割とそろってる気がする。ストレージ書き込みや他クラスターと調停してるわけだからこのくらいバラつきは誤差内だと思う。&lt;/p&gt;

&lt;h2 id=&#34;まとめ&#34;&gt;まとめ&lt;/h2&gt;

&lt;p&gt;トランザクションのロックかけるとこに時間がかかってる(200[ms]弱)ぽい。そりゃそうだ。&lt;/p&gt;

&lt;p&gt;それを差し引けば1件あたりの挿入はそんなに遅くない（250[ns]くらい）&lt;/p&gt;

&lt;p&gt;100万件つっこむの難しい。たぶんReliableQueueのほうはつっこめる気がするから、いったんキューイングしてから順々にReliableDictionaryに書き込むバージョンを明日試してみようと思う。&lt;/p&gt;

&lt;h2 id=&#34;使用コード&#34;&gt;使用コード&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-cs&#34;&gt;using System;
using System.Collections.Generic;
using System.Fabric;
using System.Linq;
using System.Threading;
using System.Threading.Tasks;
using Microsoft.ServiceFabric.Data.Collections;
using Microsoft.ServiceFabric.Services.Communication.Runtime;
using Microsoft.ServiceFabric.Services.Runtime;
using System.Runtime.Serialization;
using System.Diagnostics;
using Serilog;

namespace StatefullCollectionSample
{
  [DataContract]
  public class Sample
  {
    [DataMember]
    public long Id { get; set; }
    [DataMember]
    public string Text { get; set; }
    [DataMember]
    public DateTime DateTime { get; set; }

    public static IEnumerable&amp;lt;Sample&amp;gt; CreateSamples(int size)
    {
      var seed = 1024;
      var rand = new Random(seed);
      var anchorDate = new DateTime(2016, 1, 1).ToBinary();
      return Enumerable.Range(1, size).Select(i =&amp;gt; new Sample
      {
        Id = i,
        Text = $&amp;quot;Sample Text {i}&amp;quot;,
        DateTime = DateTime.FromBinary(anchorDate + rand.Next(-1000000, 1000000) * 3000000000)
      }).ToList();
    }
  }
  internal sealed class StatefullCollectionSample : StatefulService
  {
    public StatefullCollectionSample(StatefulServiceContext context)
      : base(context)
    { }

    protected override IEnumerable&amp;lt;ServiceReplicaListener&amp;gt; CreateServiceReplicaListeners()
    {
      return new ServiceReplicaListener[0];
    }
    IEnumerable&amp;lt;IEnumerable&amp;lt;T&amp;gt;&amp;gt; Div&amp;lt;T&amp;gt;(IEnumerable&amp;lt;T&amp;gt; items, int size)
    {
      var count = items.Count();
      var pageMax = count / size + Math.Min(count % size, 1);
      for (var i = 0; i &amp;lt; pageMax; i++)
      {
        yield return items.Skip(size * i).Take(size);
      }
    }
    protected override async Task RunAsync(CancellationToken cancellationToken)
    {
      var log = new LoggerConfiguration().WriteTo.Logentries(&amp;quot;&amp;lt;API_KEY&amp;gt;&amp;quot;).CreateLogger();
      var collection = await this.StateManager.GetOrAddAsync&amp;lt;IReliableDictionary&amp;lt;long, Sample&amp;gt;&amp;gt;(&amp;quot;Samples&amp;quot;);
      var Samples = Sample.CreateSamples(1000000);
      var sw = new Stopwatch();

      log.Information(&amp;quot;initialzed!&amp;quot;);
      while (true)
      {
        foreach (var size in new int[] { 1, 100, 1000, 10000, 100000, 1000000 })
        {
          sw.Start();
          var samples = Samples.Take(size);
          int unitSize = 50000, max = size / unitSize + Math.Min(size % unitSize, 1), count = 0;
          foreach(var unit in Div(samples, unitSize))
          {
            cancellationToken.ThrowIfCancellationRequested();
            using (var tx = this.StateManager.CreateTransaction())
            {
              var tasks = unit.Select(s =&amp;gt; 
                collection.AddOrUpdateAsync(tx, s.Id, s, (key, value) =&amp;gt; value)).ToArray();
              Task.WaitAll(tasks);
              await tx.CommitAsync();
            }
            log.Information($&amp;quot;size={size}, progress={++count}/{max}&amp;quot;);
            ServiceEventSource.Current.ServiceMessage(this, $&amp;quot;size={size}, progress={count}/{max}&amp;quot;);
          }

          sw.Stop();
          log.Information($&amp;quot;Complete (size={size}, time={sw.ElapsedMilliseconds}[ms])&amp;quot;);
          ServiceEventSource
            .Current
            .ServiceMessage(this, $&amp;quot;Complete (size={size}, time={sw.ElapsedMilliseconds}[ms])&amp;quot;);
          sw.Reset();
          await Task.Delay(TimeSpan.FromSeconds(1), cancellationToken);
        }

        await Task.Delay(TimeSpan.FromSeconds(1), cancellationToken);
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>ReliableDictionaryの走査速度の調査</title>
      <link>https://iwate.github.io/post/service-fabric-1/</link>
      <pubDate>Fri, 23 Sep 2016 12:16:59 +0900</pubDate>
      
      <guid>https://iwate.github.io/post/service-fabric-1/</guid>
      <description>&lt;p&gt;調査といってもそんなたいそうなことではない。
デバッグ実行して実行時間測っただけ。&lt;br /&gt;
アイテム数を100-&amp;gt;1000-&amp;gt;10000-&amp;gt;100000-&amp;gt;1000000と増やしていき、1カラムのフィルタリング（つまり&lt;code&gt;SELECT * FROM [DICT] WHERE &amp;lt;COLUMN_CONDITION&amp;gt;&lt;/code&gt;）にかかる時間を測る。
&lt;/p&gt;

&lt;h2 id=&#34;結果&#34;&gt;結果&lt;/h2&gt;

&lt;p&gt;とりあえず結果。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;size&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;time[ms]&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;relative value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;100&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.00&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1k&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;64&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.6&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;10k&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;574&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;95.7&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;100k&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1005&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;168&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1M&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5862&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;977&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&#34;https://iwate.github.io/images/service-fabric-1/1.png&#34; alt=&#34;グラフ&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;なんか例外吐いてリサイクル&#34;&gt;なんか例外吐いてリサイクル&lt;/h2&gt;

&lt;p&gt;一度に大量にWriteするとServiceが頻繁に例外吐いてリサイクルされる。なんじゃこりゃ。&lt;/p&gt;

&lt;h3 id=&#34;system-runtime-interopservices-comexception&#34;&gt;System.Runtime.InteropServices.COMException&amp;rsquo;&lt;/h3&gt;

&lt;p&gt;登録されているサービス タイプの名前が、サービス マニフェストと一致していないときに吐くらしい。&lt;/p&gt;

&lt;h3 id=&#34;system-fabric-fabrictransientexception&#34;&gt;System.Fabric.FabricTransientException&lt;/h3&gt;

&lt;p&gt;クォーラム損失発生した時に起こるらしい。
以下引用&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;クォーラムの損失&lt;/strong&gt;&lt;br /&gt;
ステートフル サービスのパーティションのレプリカの過半数がダウンした場合、そのパーティションは &amp;ldquo;クォーラム損失&amp;rdquo; と呼ばれる状態になります。 この時点で、Service Fabric はそのパーティションへの書き込み許可を停止し、パーティションの一貫性と信頼性が保たれるようにします。実際には、クライアントのデータが本当は保存されていないのに保存されたものとしてクライアントに通知されないよう、使用不可能な期間を受け入れるようになっています。管理者がそのステートフル サービスのセカンダリ レプリカからの読み取りを許可している場合、この状態の間も読み取り操作の実行を続けられることに注意してください。十分な数のレプリカが復旧するまで、またはクラスターの管理者が Repair-ServiceFabricPartition API.を使って強制的にシステムを使用できるようにするまで、パーティションはクォーラム損失状態のままになります。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;警告:
プライマリ レプリカがダウンしたときに修復アクションを実行すると、データの損失が発生します。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;システム サービスでもクォーラム損失が発生する可能性があり、その影響は問題のあるサービスに固有です。たとえば、ネーム サービスでクォーラム損失が発生すると名前の解決に影響があり、フェールオーバー マネージャー サービスの場合は新しいサービスの作成とフェールオーバーがブロックされます。ユーザー独自のサービスとは異なり、システム サービスは &amp;ldquo;修復しない&amp;rdquo; ことをお勧めします。代わりに、単にダウンしたレプリカが復旧するまで待つことをお勧めします。&lt;br /&gt;
&lt;a href=&#34;https://azure.microsoft.com/ja-jp/documentation/articles/service-fabric-disaster-recovery/&#34;&gt;https://azure.microsoft.com/ja-jp/documentation/articles/service-fabric-disaster-recovery/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;所感&#34;&gt;所感&lt;/h2&gt;

&lt;p&gt;Read自体は線形ですね。そりゃそうだ。ただ、かなり遅いですね。&lt;br /&gt;
そもそも、そんなに数入れて使うもんじゃないのかなあ…&lt;/p&gt;

&lt;p&gt;Readが線形なのはいいんですけど&lt;code&gt;Enumerator&lt;/code&gt;だし。それよりWriteがすごく遅いのが気になる。100万件入れるのにすごく時間がかかったので、Writeについてもうちょい調べよう。&lt;/p&gt;

&lt;h2 id=&#34;使用コード&#34;&gt;使用コード&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-cs&#34;&gt;using System;
using System.Collections.Generic;
using System.Fabric;
using System.Linq;
using System.Threading;
using System.Threading.Tasks;
using Microsoft.ServiceFabric.Data.Collections;
using Microsoft.ServiceFabric.Services.Communication.Runtime;
using Microsoft.ServiceFabric.Services.Runtime;
using System.Diagnostics;

namespace FabricSample.Service
{
  internal sealed class Service : StatefulService
  {
    public Service(StatefulServiceContext context)
      : base(context)
    { }
    protected override IEnumerable&amp;lt;ServiceReplicaListener&amp;gt; CreateServiceReplicaListeners()
    {
      return new ServiceReplicaListener[0];
    }
    IEnumerable&amp;lt;IEnumerable&amp;lt;T&amp;gt;&amp;gt; Div&amp;lt;T&amp;gt;(IEnumerable&amp;lt;T&amp;gt; items, int size)
    {
      var count = items.Count();
      var pageMax = count / size + Math.Min(count % size, 1);
      for(var i = 0; i &amp;lt; pageMax; i++)
      {
        yield return items.Skip(size * i).Take(size);
      }
    }
    protected override async Task RunAsync(CancellationToken cancellationToken)
    {
      var collection = 
            await this.StateManager.GetOrAddAsync&amp;lt;IReliableDictionary&amp;lt;long, Item&amp;gt;&amp;gt;(&amp;quot;SampleItems&amp;quot;);
      var items = SampleItemsFactory.CreateItems(1000000);
      var max = items.Count();
      var sw = new Stopwatch();

      long current = 0;
      using (var tx = StateManager.CreateTransaction())
      {
        current = await collection.GetCountAsync(tx);
      }
      var progress = (double)current / max;
      var size = Math.Max((int)((1- progress) * (1 - progress) * 10000), 100);
      int count = (int)current / size;
      
      // 書き込んでる最中に死ぬので、
      // リサイクルが起こるごとに書き込みサイズを小さくして前回の途中から挿入していく。
      foreach (var _items in Div(items, size).Skip(count))
      {
        sw.Start();
        using (var tx = StateManager.CreateTransaction())
        {
          cancellationToken.ThrowIfCancellationRequested();
          var tasks = _items.Select(item =&amp;gt; 
                                      collection.AddOrUpdateAsync(tx, item.Id, item, (key, old) =&amp;gt; item));
          Task.WaitAll(tasks.ToArray());
          await tx.CommitAsync();
        }
        sw.Stop();
        ServiceEventSource
          .Current
          .ServiceMessage(this, $&amp;quot;Initialized {++count * size}/{max}  {sw.ElapsedMilliseconds}[ms]&amp;quot;);
        sw.Reset();
      }
          
      ServiceEventSource.Current.ServiceMessage(this, $&amp;quot;Initialized All&amp;quot;);

      var today = DateTime.Today;
      var thisweek = today.AddDays(7);
      var list = new List&amp;lt;Item&amp;gt;();

      while (true)
      {
        cancellationToken.ThrowIfCancellationRequested();
        sw.Start();
        using (var tx = StateManager.CreateTransaction())
        {
          var @enum = (await collection.CreateEnumerableAsync(tx)).GetAsyncEnumerator();
          while (await @enum.MoveNextAsync(cancellationToken))
          {
            var item = @enum.Current.Value;
            if (today &amp;lt;= item.DateTime &amp;amp;&amp;amp; item.DateTime &amp;lt; thisweek)
                list.Add(item);
          }
        }
        sw.Stop();
        ServiceEventSource
          .Current
          .ServiceMessage(this, $&amp;quot;items.count = {list.Count}, time = {sw.ElapsedMilliseconds}[ms]&amp;quot;);
        sw.Reset();
        list.Clear();
        await Task.Delay(TimeSpan.FromMilliseconds(100), cancellationToken);
      }
    }
  }
}

&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Hello World</title>
      <link>https://iwate.github.io/post/hello-world/</link>
      <pubDate>Fri, 23 Sep 2016 12:02:46 +0900</pubDate>
      
      <guid>https://iwate.github.io/post/hello-world/</guid>
      <description>&lt;p&gt;Github Pagesにブログ立ててみようかなと思って&lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt;を使ってみてる。
&lt;/p&gt;

&lt;h2 id=&#34;テーマ&#34;&gt;テーマ&lt;/h2&gt;

&lt;p&gt;テーマには&lt;a href=&#34;http://themes.gohugo.io/hemingway/&#34;&gt;Hemingway&lt;/a&gt;を使ってみる。&lt;/p&gt;

&lt;h2 id=&#34;コードハイライト&#34;&gt;コードハイライト&lt;/h2&gt;

&lt;p&gt;Hemingwayはhighlight.jsに対応してるみたい。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cs:hello.cs&#34;&gt;using System;
class Program
{
  public static void Main(string[] args)
  {
    Console.WriteLine(&amp;quot;Hello, World!&amp;quot;);
  }
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
  </channel>
</rss>